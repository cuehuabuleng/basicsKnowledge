HashMap的数据结构：数组+(链表或者红黑树)

    数组：查询效率高，插入删除效率低
    链表：查询效率低，插入删除效率高

    hashmap是一个键值对的集合，里面的每个子项可以称为hash桶(hash_table)

1、储存的原理 hash.set(key,value)

    (1)、得到key
    (2)、首先通过hash函数得到这个key值的hash值
    (3)、然后将这个hash值进行取模运算，得到桶号（hash值对桶数求摸）
    (4)、根据桶号存放key和value值


    在向hash表里面存放值的时候，可能会发生hash冲突：当在第二步计算hash值的时候，出现不同对象key计算出来的hash值是一样的，所以计算出来的桶号可能已经有元素在里面了，这这种情况就是hash冲突了。
        这时候需要使用equals进行比较。默认的比较规则就是比较两个的对象地址，也就是说需要是同一个对象才相等。

        (1)、如果是相等的话那就直接覆盖就行了。
        (2)、如果两泽不相等，那就在原来的元素下面使用链表的结构储存该元素。hash桶里面的每个元素节点都会有有一个next指针指向下一个节点，这就会形成一个链表。当链表里面的元素个数达到了8个之后，就就会将链表储存转换成红黑数树来储存，原因是红黑树是平衡二叉树，在查找性能方面比链表的高。


2、取值的过程 get

    (1)、得到key值
    (2)、通过hash函数对key值进行运算得到一个hash值
    (3)、通过hash值与桶数的求摸运算得到桶号
    (4)、比较桶内的元素是否与key相等，如果不相等，那就没有找到
    (5)、取出相应的value




3、hash扩容： 
    HashMap中的两个重要的参数：HashMap中有两个重要的参数：初始容量大小和加载因子，初始容量大小是创建时给数组分配的容量大小，默认值为16，用数组容量大小乘以加载因子得到一个值，一旦数组中存储的元素个数超过该值就会调用rehash方法将数组容量增加到原来的两倍，专业术语叫做扩容.

    在做扩容的时候会生成一个新的数组，原来的所有数据需要重新计算哈希码值重新分配到新的数组，所以扩容的操作非常消耗性能.


问题：为什么hash Map的查找时间复杂是o(1)

    上面说了HashMap的查询大概分成四步：
    1、判断key，根据key计算出对应的桶号
    2、根据桶号得到对应位置的键值对链表
    3、遍历链表，根据key找到相对应的键值对。
    4、拿到value


    要保证上面的四步的时间复杂度一共为O(1),就需要保证每一步的时间复杂度都为O(1)，。主要是看第三步，查找链表的时候的时间复杂度。但是查找链表的时间复杂度是o(n)，与链表的长度有关。所以我们要保证那个链表的长度为1，就可以满足整个hashMap查找的时间复杂度为o(1)。
    
    但是HashMap的查找时间复杂度只有在最理想的情况下才会为o(1)。

    但是在hashmap的文档里面有这么一段描述，每个哈希桶中元素数量是成泊松分布的,
    listSize = (exp(-0.5) * pow(0.5, k) / * factorial(k))，
s        不同数量出现的概率如下：

        * 0:    0.60653066
        * 1:    0.30326533
        * 2:    0.07581633
        * 3:    0.01263606
        * 4:    0.00157952
        * 5:    0.00015795
        * 6:    0.00001316
        * 7:    0.00000094
        * 8:    0.00000006
        大于8: <千万分之1

    通过上面的统计可以看出，hashMap的键值正常(不同对象的hash值不同的情况)，哈希桶的数量超过8个的概率低于千万分之一，所以我们通常认为hashmap的查询时间复杂度为O(1)




    https://blog.csdn.net/li_huai_dong/article/details/79910626
    https://zhuanlan.zhihu.com/p/79507868

    https://blog.csdn.net/john1337/article/details/104727895